{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5221e7c2-eee9-4ce7-8c15-a38200ea4f41",
   "metadata": {},
   "source": [
    "# Q1: Explain the following with an example:\n",
    "1. Artificial Intelligence\n",
    "2. Machine Learning\n",
    "3. Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95754f9d-b1aa-441a-a505-334529c80982",
   "metadata": {},
   "source": [
    "A1:\n",
    "1. Artificial Intelligence (AI):\n",
    "\n",
    "- Definition: Artificial Intelligence refers to the simulation of human intelligence in machines, enabling them to perform tasks that typically require human intelligence, such as understanding natural language, recognizing patterns, making decisions, and learning from experience.\n",
    "- Example: Virtual Personal Assistants like Siri, Google Assistant, and Alexa are AI applications. They can understand and respond to voice commands, provide information, set reminders, and even engage in natural language conversations.\n",
    "\n",
    "2. Machine Learning (ML):\n",
    "\n",
    "- Definition: Machine Learning is a subset of AI that focuses on the development of algorithms and statistical models that allow computers to learn and make predictions or decisions without being explicitly programmed. ML algorithms improve their performance through experience and data.\n",
    "- Example: Spam email filters use machine learning to identify and filter out spam messages. These filters analyze characteristics of emails (e.g., content, sender, subject) and learn from user feedback to improve accuracy over time. As they process more data, they become better at classifying emails as spam or not.\n",
    "\n",
    "3. Deep Learning (DL):\n",
    "\n",
    "- Definition: Deep Learning is a subfield of machine learning that involves artificial neural networks with many layers (deep neural networks). These networks are designed to automatically learn hierarchical representations of data, making them especially powerful for tasks like image and speech recognition.\n",
    "- Example: Image recognition in self-driving cars is a common use case for deep learning. Convolutional Neural Networks (CNNs), a type of deep learning model, can analyze visual data from cameras on the car to identify objects like pedestrians, other vehicles, road signs, and traffic lights. The deep layers of the neural network can detect intricate patterns and features in images, allowing the car to make real-time decisions based on what it \"sees.\"\n",
    "\n",
    "In summary, Artificial Intelligence encompasses the broader concept of creating machines that can mimic human intelligence. Machine Learning is a subset of AI focused on building models that learn from data to make predictions or decisions. Deep Learning is a subfield of machine learning that utilizes deep neural networks to handle complex tasks like image and speech recognition. These three concepts are interrelated and form the foundation for many modern applications across various industries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3e119-a735-4b68-a17d-03e9cf1cdaa6",
   "metadata": {},
   "source": [
    "# Q2: What is supervised learning? List some examples of supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd344fb0-9560-44e5-946a-f475aa63acf6",
   "metadata": {},
   "source": [
    "A2 : \n",
    "Supervised learning is a type of machine learning where an algorithm learns from a labeled dataset, which means that each input data point in the dataset is associated with a corresponding target or output label. The goal of supervised learning is to learn a mapping function from input to output that can make predictions or classify new, unseen data accurately.\n",
    "\n",
    "In supervised learning, the algorithm is trained on historical data where the correct answers (labels) are known. During training, the algorithm adjusts its internal parameters to minimize the error or discrepancy between its predictions and the actual labels. Once trained, the algorithm can be used to make predictions or classifications on new, unlabeled data.\n",
    "\n",
    "Examples of supervised learning tasks include:\n",
    "\n",
    "- Classification: This task involves assigning data points to predefined categories or classes. \n",
    "\n",
    "Some examples include:\n",
    "\n",
    "Email spam detection: Classifying emails as spam or not spam.\n",
    "\n",
    "Image classification: Identifying objects in images (e.g., cats, dogs, cars).\n",
    "\n",
    "Medical diagnosis: Diagnosing diseases based on patient data (e.g., cancer detection).\n",
    "\n",
    "- Regression: Regression tasks involve predicting a continuous numerical value. \n",
    "\n",
    "Examples include:\n",
    "\n",
    "Predicting house prices: Given features like size, location, and number of bedrooms, predicting the sale price of a house.\n",
    "\n",
    "Stock price prediction: Forecasting the future price of a stock based on historical data.\n",
    "\n",
    "Weather forecasting: Predicting temperature, rainfall, or other weather-related variables.\n",
    "\n",
    "Natural Language Processing (NLP): NLP tasks in supervised learning include:\n",
    "\n",
    "- Sentiment analysis: Determining the sentiment (positive, negative, neutral) of text or social media posts.\n",
    "\n",
    "- Named entity recognition: Identifying and categorizing entities like names of people, organizations, or locations in text.\n",
    "\n",
    "- Recommendation Systems: Recommender systems predict what items or content a user might be interested in. Examples include:\n",
    "\n",
    "- Movie recommendations: Suggesting movies to users based on their viewing history.\n",
    "\n",
    "- E-commerce product recommendations: Recommending products to online shoppers based on their browsing and purchase history.\n",
    "\n",
    "- Speech Recognition: Converting spoken language into text, used in applications like voice assistants (e.g., Siri, Alexa) and transcription services.\n",
    "\n",
    "- Handwriting Recognition: Recognizing handwritten characters or words, often used in digitizing handwritten documents.\n",
    "\n",
    "- Fraud Detection: Identifying fraudulent transactions in financial data by analyzing patterns and anomalies.\n",
    "\n",
    "In all these examples, the supervised learning algorithm learns from labeled data to make predictions or decisions on new, unseen data. The choice of algorithm and the quality and quantity of the training data play a crucial role in the success of supervised learning applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192e705-a27d-44c8-a100-14ead08be80e",
   "metadata": {},
   "source": [
    "# Q3: What is unsupervised learning? List some examples of unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c229f3-44b2-44a1-9a75-59306b091893",
   "metadata": {},
   "source": [
    "A3:\n",
    "Unsupervised learning is a type of machine learning where the algorithm is trained on unlabeled data, which means that the training dataset does not contain explicit output labels or target values. Instead, the algorithm tries to find patterns, structures, or relationships within the data without any specific guidance or supervision. The primary goal of unsupervised learning is to discover inherent structures and hidden insights in the data.\n",
    "\n",
    "- Examples of unsupervised learning tasks include:\n",
    "\n",
    "1. Clustering: Clustering is the process of grouping similar data points together based on their features or characteristics. \n",
    "\n",
    "Some examples include:\n",
    "\n",
    "- Customer segmentation: Identifying groups of customers with similar purchasing behavior for targeted marketing.\n",
    "\n",
    "- Document clustering: Grouping similar documents together for content organization or topic modeling.\n",
    "\n",
    "- Image segmentation: Dividing an image into regions with similar attributes, often used in computer vision.\n",
    "\n",
    "2. Dimensionality Reduction: Dimensionality reduction techniques aim to reduce the number of features or variables in the data while preserving its essential information. \n",
    "\n",
    "Examples include:\n",
    "\n",
    "- Principal Component Analysis (PCA): Reducing the dimensionality of high-dimensional data to simplify analysis or visualization.\n",
    "\n",
    "- t-SNE (t-distributed Stochastic Neighbor Embedding): Visualizing high-dimensional data in lower dimensions while preserving relationships.\n",
    "\n",
    "3. Anomaly Detection: Anomaly detection identifies data points that deviate significantly from the norm or exhibit unusual behavior. \n",
    "\n",
    "Applications include:\n",
    "\n",
    "- Network intrusion detection: Detecting abnormal network activities or security breaches.\n",
    "\n",
    "- Fraud detection: Identifying unusual credit card transactions or financial anomalies.\n",
    "\n",
    "4. Association Rule Mining: This involves discovering interesting relationships or associations between items in a dataset. \n",
    "\n",
    "Examples include:\n",
    "\n",
    "- Market basket analysis: Identifying item associations in retail sales data to make product placement or bundling decisions.\n",
    "\n",
    "- Recommender systems: Discovering item associations to suggest related products to customers.\n",
    "\n",
    "5. Density Estimation: Density estimation methods aim to model the underlying probability distribution of the data. \n",
    "\n",
    "Examples include:\n",
    "\n",
    "- Gaussian Mixture Models (GMM): Modeling data as a combination of multiple Gaussian distributions.\n",
    "\n",
    "- Kernel Density Estimation (KDE): Estimating the probability density function of data points.\n",
    "\n",
    "6. Topic Modeling: Uncovering topics or themes within a collection of text documents, often used in natural language processing (NLP) applications like:\n",
    "\n",
    "- Latent Dirichlet Allocation (LDA): Identifying topics in a corpus of documents.\n",
    "\n",
    "Unsupervised learning is valuable for exploring and understanding complex datasets, uncovering hidden patterns, and generating insights from unstructured or unlabeled data. It is a fundamental component in various data analysis and machine learning applications, especially when there is no readily available labeled data for training.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e81eb-6aae-4cde-98b2-ee4e793709c7",
   "metadata": {},
   "source": [
    "# Q4: What is the difference between AI, ML, DL, and DS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aa762e-5131-4c67-ac86-843c1dcec8e5",
   "metadata": {},
   "source": [
    "A4:\n",
    "\n",
    "AI (Artificial Intelligence), ML (Machine Learning), DL (Deep Learning), and DS (Data Science) are related but distinct fields within the broader domain of computer science and data analysis. Here are the key differences between them:\n",
    "\n",
    "# Artificial Intelligence (AI):\n",
    "\n",
    "- Definition: AI is a broad field of computer science that aims to create machines or systems capable of performing tasks that typically require human intelligence, such as reasoning, problem-solving, understanding natural language, and learning from experience.\n",
    "- Scope: AI encompasses a wide range of techniques, including rule-based systems, expert systems, knowledge representation, and more.\n",
    "- Example: Virtual personal assistants like Siri or self-driving cars like Tesla's Autopilot are applications of AI.\n",
    "\n",
    "# Machine Learning (ML):\n",
    "\n",
    "- Definition: ML is a subset of AI that focuses on the development of algorithms and statistical models that allow computers to learn and make predictions or decisions without being explicitly programmed. ML algorithms improve their performance through experience and data.\n",
    "- Scope: ML includes supervised learning, unsupervised learning, reinforcement learning, and more. It's a key component of AI that enables systems to learn from data.\n",
    "- Example: Spam email filters, recommendation systems, and image classifiers are built using ML techniques.\n",
    "\n",
    "# Deep Learning (DL):\n",
    "\n",
    "- Definition: Deep Learning is a subfield of ML that involves artificial neural networks with many layers (deep neural networks). These networks are designed to automatically learn hierarchical representations of data, making them especially powerful for tasks like image and speech recognition.\n",
    "- Scope: DL is a specialized branch of ML that excels in handling complex data with multiple levels of abstraction. It often requires large amounts of labeled data and computational resources.\n",
    "- Example: Convolutional Neural Networks (CNNs) for image recognition and Recurrent Neural Networks (RNNs) for natural language processing are examples of deep learning models.\n",
    "\n",
    "# Data Science (DS):\n",
    "\n",
    "- Definition: Data Science is an interdisciplinary field that combines domain knowledge, programming skills, statistical analysis, and ML techniques to extract insights and knowledge from data. It involves data collection, cleaning, exploration, and modeling.\n",
    "- Scope: Data Science covers a wide range of activities, including data analysis, data visualization, data engineering, and ML model development. It often aims to solve specific business or research problems.\n",
    "- Example: A data scientist might analyze customer data to uncover trends, build predictive models for sales forecasting, or develop recommendation systems for an e-commerce platform.\n",
    "\n",
    "In summary, AI is the overarching field that encompasses efforts to create intelligent machines. ML is a subset of AI that focuses on algorithmic learning from data, while DL is a specialized subset of ML that leverages deep neural networks. Data Science is a multidisciplinary field that involves collecting, analyzing, and extracting insights from data, often using ML and statistical techniques to solve practical problems. These fields often overlap and complement each other in various applications and research areas.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe531c-8b41-41cf-aff8-82218b06928c",
   "metadata": {},
   "source": [
    "# Q5: What are the main differences between supervised, unsupervised, and semi-supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0c2f6-db2c-403c-bb12-3ccf04834329",
   "metadata": {},
   "source": [
    "A5:\n",
    "\n",
    "Supervised learning, unsupervised learning, and semi-supervised learning are three different types of machine learning paradigms, each with its own characteristics and applications. Here are the main differences between them:\n",
    "\n",
    "# Supervised Learning:\n",
    "- Data Labeling: Supervised learning relies on a labeled dataset, where each input data point is associated with a corresponding output label or target value.\n",
    "- Objective: The goal of supervised learning is to learn a mapping or relationship between inputs and outputs, so the algorithm can make predictions or classify new, unseen data accurately.\n",
    "- Examples: Classification (e.g., spam detection, image recognition) and regression (e.g., price prediction) are common supervised learning tasks.\n",
    "- Supervision: It requires strong supervision because the algorithm learns from explicit labels during training.\n",
    "# Unsupervised Learning:\n",
    "- Data Labeling: Unsupervised learning uses unlabeled data, which means the training dataset does not contain explicit output labels or target values.\n",
    "- Objective: The primary goal of unsupervised learning is to discover hidden patterns, structures, or relationships within the data without guidance or supervision.\n",
    "- Examples: Clustering (e.g., customer segmentation), dimensionality reduction (e.g., PCA), and density estimation (e.g., Gaussian Mixture Models) are common unsupervised learning tasks.\n",
    "- Supervision: It does not require explicit supervision, and the algorithm explores the data's intrinsic properties.\n",
    "# Semi-Supervised Learning:\n",
    "- Data Labeling: Semi-supervised learning combines both labeled and unlabeled data in the training dataset. Typically, there is a small amount of labeled data and a larger amount of unlabeled data.\n",
    "- Objective: The goal is to leverage the limited labeled data to improve the model's performance on tasks that would otherwise rely solely on unsupervised learning.\n",
    "- Examples: Semi-supervised learning can be applied to various tasks, including classification, where it's beneficial when labeling data is expensive or time-consuming.\n",
    "- Supervision: It involves partial supervision, as it uses labeled data for some tasks and relies on unsupervised learning principles for others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e586f-4437-4657-86fa-ba8d8933d479",
   "metadata": {},
   "source": [
    "# Q6: What is train, test and validation split? Explain the importance of each term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f2aeab-08ec-44af-a056-9fca6ec1b0f3",
   "metadata": {},
   "source": [
    "A6:\n",
    "\n",
    "In machine learning, the process of splitting a dataset into three main subsets — training set, validation set, and test set — is crucial for model development, evaluation, and optimization. Each subset serves a specific purpose, and their proper allocation is important to build and assess machine learning models effectively. Here's an explanation of each term and their importance:\n",
    "\n",
    "# Training Set:\n",
    "\n",
    "- Purpose: The training set is the largest portion of the dataset and is used to train the machine learning model. It serves as the input for the model to learn the underlying patterns, relationships, and features in the data.\n",
    "- Importance: The training set is critical because it is where the model learns from the labeled data. During training, the model adjusts its internal parameters to minimize the error between its predictions and the actual target values. A well-trained model should capture the data's patterns without overfitting (fitting the training data too closely) or underfitting (failing to capture the data's patterns).\n",
    "\n",
    "# Validation Set:\n",
    "\n",
    "- Purpose: The validation set is a smaller subset of the dataset that is used to fine-tune the model's hyperparameters and assess its generalization performance during the training process.\n",
    "- Importance: The validation set helps prevent overfitting and guides the model selection process. By evaluating the model on the validation set, you can make adjustments to hyperparameters (e.g., learning rate, regularization strength) and monitor its performance on data it has not seen during training. This enables you to select the best-performing model for your task.\n",
    "\n",
    "# Test Set:\n",
    "\n",
    "- Purpose: The test set is a separate portion of the dataset that is not used during model development or parameter tuning. It is kept aside until the model is fully trained and hyperparameters are optimized.\n",
    "- Importance: The test set serves as an independent evaluation dataset to assess the model's generalization performance on unseen data. It provides an unbiased estimate of how well the model is likely to perform in the real world or on new, unseen examples. It helps you understand how well the model has learned and whether it exhibits any overfitting issues.\n",
    "\n",
    "# Importance of Each Term:\n",
    "\n",
    "- Training Set: This is the foundation of model development. Without a sufficient and representative training set, the model cannot learn the patterns in the data.\n",
    "- Validation Set: It guides the model development process and helps fine-tune hyperparameters. It acts as a check to ensure that the model doesn't overfit the training data.\n",
    "- Test Set: This provides an unbiased evaluation of the model's performance. It helps you assess how well the model is likely to perform in real-world scenarios.\n",
    "\n",
    "The three-way split into training, validation, and test sets ensures that machine learning models are developed, tuned, and evaluated rigorously and in a way that supports reliable and unbiased performance estimation. It helps you strike a balance between fitting the training data well and ensuring that the model can generalize to new, unseen data effectively.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa8bf59-ed02-4a78-99a2-9148b39e0d6c",
   "metadata": {},
   "source": [
    "# Q7: How can unsupervised learning be used in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e066e2dc-c3a9-4300-ae77-c2b3a48d2b76",
   "metadata": {},
   "source": [
    "A7:\n",
    "\n",
    "Unsupervised learning can be a valuable technique for anomaly detection, as it can help identify unusual patterns or outliers in data without the need for labeled examples of anomalies. Here's how unsupervised learning can be used for anomaly detection:\n",
    "\n",
    "1. Collect and Prepare Data:\n",
    "- Gather the data that you want to analyze for anomalies. This could be data from various sources, such as sensor readings, transaction logs, or network traffic.\n",
    "- Preprocess the data by cleaning, normalizing, and transforming it as necessary to ensure it's suitable for analysis.\n",
    "\n",
    "2. Choose an Unsupervised Learning Algorithm:\n",
    "- Select an unsupervised learning algorithm that is well-suited for anomaly detection. Common algorithms include:\n",
    "- Clustering Algorithms: Clustering methods like K-Means, DBSCAN, or Gaussian Mixture Models (GMM) can be used to group similar data points together. Anomalies are data points that do not belong to any cluster or belong to a small cluster.\n",
    "- Density-Based Methods: Algorithms like Local Outlier Factor (LOF) and Isolation Forest work by identifying data points that have significantly different densities compared to their neighbors.\n",
    "- Autoencoders: Neural network-based autoencoders can be trained to reconstruct input data. Data points that have high reconstruction errors are likely to be anomalies.\n",
    "\n",
    "3. Feature Engineering:\n",
    "- Depending on the chosen algorithm, it may be helpful to engineer relevant features or representations of the data that can aid in detecting anomalies.\n",
    "\n",
    "4. Train the Unsupervised Model:\n",
    "- Use the unsupervised learning algorithm to build a model on the prepared data. The model will learn the normal patterns and structures present in the data.\n",
    "\n",
    "5. Define a Threshold:\n",
    "- Anomalies are typically defined as data points that deviate significantly from the learned normal patterns. You can set a threshold or anomaly score beyond which data points are considered anomalies. This threshold can be determined through techniques like statistical analysis or cross-validation.\n",
    "\n",
    "6. Detect Anomalies:\n",
    "- Apply the trained model to the entire dataset or real-time data to identify anomalies based on the defined threshold. Data points that surpass this threshold are flagged as anomalies.\n",
    "\n",
    "7. Review and Validation:\n",
    "- Review the detected anomalies to ensure they are genuine and not false positives. This step may involve domain expertise to confirm whether the identified anomalies are meaningful and require action.\n",
    "\n",
    "8. Monitoring and Maintenance:\n",
    "- Anomaly detection is an ongoing process. Continuously monitor the data and the performance of the anomaly detection model. Periodically retrain the model to adapt to evolving patterns and data changes.\n",
    "\n",
    "Unsupervised learning is particularly useful for anomaly detection in scenarios where labeled anomaly data is scarce or unavailable, as it does not rely on prior knowledge of anomalies. However, it may require careful tuning and threshold setting to strike a balance between detecting true anomalies and minimizing false alarms. Additionally, it is important to consider the choice of algorithm and the quality of features when applying unsupervised learning for anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4de69ef-f114-4144-bbf9-9cb700bca7bc",
   "metadata": {},
   "source": [
    "# Q8: List down some commonly used supervised learning algorithms and unsupervised learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ac7a8c-d5b9-4f14-90e0-e8d47def99b9",
   "metadata": {},
   "source": [
    "A8:\n",
    "\n",
    "Here are some commonly used supervised and unsupervised learning algorithms:\n",
    "\n",
    "# Supervised Learning Algorithms:\n",
    "\n",
    "1. Linear Regression: Used for predicting a continuous target variable based on linear relationships between features and the target.\n",
    "\n",
    "2. Logistic Regression: Used for binary classification problems, where the target variable has two classes.\n",
    "\n",
    "3. Decision Trees: Employed for both classification and regression tasks by partitioning the feature space into a tree-like structure.\n",
    "\n",
    "4. Random Forest: An ensemble learning method that combines multiple decision trees to improve accuracy and reduce overfitting.\n",
    "\n",
    "5. Support Vector Machines (SVM): Effective for both classification and regression by finding the hyperplane that best separates data points or fits the data.\n",
    "\n",
    "6. K-Nearest Neighbors (K-NN): Used for classification and regression by considering the k-nearest data points to make predictions.\n",
    "\n",
    "7. Naive Bayes: A probabilistic classifier based on Bayes' theorem, often used for text classification and spam filtering.\n",
    "\n",
    "8. Gradient Boosting Algorithms (e.g., XGBoost, LightGBM): Ensemble methods that build multiple decision trees sequentially to improve predictive accuracy.\n",
    "\n",
    "9. Neural Networks (Deep Learning): Deep learning models like Convolutional Neural Networks (CNNs) for image data and Recurrent Neural Networks (RNNs) for sequential data.\n",
    "\n",
    "10. Linear Discriminant Analysis (LDA): Used for dimensionality reduction and classification by finding linear combinations of features that best separate classes.\n",
    "\n",
    "# Unsupervised Learning Algorithms:\n",
    "\n",
    "1. K-Means Clustering: A partitioning algorithm that groups data points into k clusters based on similarity.\n",
    "\n",
    "2. Hierarchical Clustering: Builds a hierarchy of clusters, allowing for both agglomerative (bottom-up) and divisive (top-down) approaches.\n",
    "\n",
    "3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise): Identifies clusters based on data density, making it robust to irregularly shaped clusters.\n",
    "\n",
    "4. Gaussian Mixture Models (GMM): Represents data as a mixture of Gaussian distributions, useful for modeling complex data distributions.\n",
    "\n",
    "5. Principal Component Analysis (PCA): A dimensionality reduction technique that captures the most significant variations in data by finding orthogonal linear combinations of features.\n",
    "\n",
    "6. Autoencoders: Neural network architectures used for feature learning and dimensionality reduction, often applied in deep learning.\n",
    "\n",
    "7. Isolation Forest: Anomaly detection algorithm that isolates anomalies by recursively partitioning data.\n",
    "\n",
    "8. Local Outlier Factor (LOF): Identifies anomalies by comparing the density of data points with their neighbors.\n",
    "\n",
    "9. t-SNE (t-distributed Stochastic Neighbor Embedding): Dimensionality reduction technique for visualization and exploring high-dimensional data.\n",
    "\n",
    "10. Self-Organizing Maps (SOM): Neural network-based technique for clustering and visualizing high-dimensional data.\n",
    "\n",
    "These are just a selection of commonly used supervised and unsupervised learning algorithms. The choice of algorithm depends on the specific problem, data characteristics, and goals of your machine learning or data analysis task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2db3e-18b2-4a73-8927-e528c7bbbbfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
